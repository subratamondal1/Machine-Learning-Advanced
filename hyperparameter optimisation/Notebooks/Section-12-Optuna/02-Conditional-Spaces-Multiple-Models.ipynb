{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters for different ML models\n",
    "\n",
    "In this notebook, we will use the define-by-run framework to optimize the hyperparameters of various machine learning models from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the objective function takes the hyperparameter space\n",
    "# as input\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"logit\", \"RF\", 'GBM'])\n",
    "    \n",
    "    if classifier_name == \"logit\":\n",
    "        \n",
    "        logit_penalty = trial.suggest_categorical('logit_penalty', ['l1','l2'])\n",
    "        logit_c = trial.suggest_float('logit_c', 0.001, 10)\n",
    "        logit_solver = 'saga'\n",
    "        \n",
    "        model = LogisticRegression(\n",
    "            penalty=logit_penalty,\n",
    "            C=logit_c,\n",
    "            solver=logit_solver,\n",
    "        )\n",
    "        \n",
    "    elif classifier_name ==\"RF\":\n",
    "        \n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 100, 1000)\n",
    "        rf_criterion = trial.suggest_categorical(\"rf_criterion\", ['gini', 'entropy'])\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 1, 4)\n",
    "        rf_min_samples_split = trial.suggest_float(\"rf_min_samples_split\", 0.01, 1)\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=rf_n_estimators,\n",
    "            criterion=rf_criterion,\n",
    "            max_depth=rf_max_depth,\n",
    "            min_samples_split=rf_min_samples_split,\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        gbm_n_estimators = trial.suggest_int(\"gbm_n_estimators\", 100, 1000)\n",
    "        gbm_criterion = trial.suggest_categorical(\"gbm_criterion\", ['mse', 'friedman_mse'])\n",
    "        gbm_max_depth = trial.suggest_int(\"gbm_max_depth\", 1, 4)\n",
    "        gbm_min_samples_split = trial.suggest_float(\"gbm_min_samples_split\", 0.01, 1)\n",
    "\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=gbm_n_estimators,\n",
    "            criterion=gbm_criterion,\n",
    "            max_depth=gbm_max_depth,\n",
    "            min_samples_split=gbm_min_samples_split,\n",
    "        )\n",
    "\n",
    "    \n",
    "    score = cross_val_score(model, X_train, y_train, cv=3)\n",
    "    accuracy = score.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPE\n",
    "\n",
    "TPESampler is the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-20 13:53:31,353]\u001b[0m A new study created in memory with name: no-name-fbf66387-b401-442f-affd-75fd9ba26c9d\u001b[0m\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-05-20 13:53:31,434]\u001b[0m Trial 0 finished with value: 0.9120148856990963 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 6.072657399731582}. Best is trial 0 with value: 0.9120148856990963.\u001b[0m\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-05-20 13:53:31,529]\u001b[0m Trial 1 finished with value: 0.9120148856990963 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 7.331767730718092}. Best is trial 0 with value: 0.9120148856990963.\u001b[0m\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-05-20 13:53:31,606]\u001b[0m Trial 2 finished with value: 0.9120148856990963 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 7.617337107023225}. Best is trial 0 with value: 0.9120148856990963.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:33,444]\u001b[0m Trial 3 finished with value: 0.9623110807321332 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 356, 'gbm_criterion': 'mse', 'gbm_max_depth': 2, 'gbm_min_samples_split': 0.26072809348624476}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:34,205]\u001b[0m Trial 4 finished with value: 0.6256360598465861 and parameters: {'classifier': 'RF', 'rf_n_estimators': 145, 'rf_criterion': 'gini', 'rf_max_depth': 3, 'rf_min_samples_split': 0.7539175774949091}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:35,448]\u001b[0m Trial 5 finished with value: 0.9171223513328776 and parameters: {'classifier': 'RF', 'rf_n_estimators': 267, 'rf_criterion': 'gini', 'rf_max_depth': 1, 'rf_min_samples_split': 0.5923718652861498}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:38,711]\u001b[0m Trial 6 finished with value: 0.6256360598465861 and parameters: {'classifier': 'RF', 'rf_n_estimators': 798, 'rf_criterion': 'entropy', 'rf_max_depth': 4, 'rf_min_samples_split': 0.8947303290750759}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:42,948]\u001b[0m Trial 7 finished with value: 0.9472924736082632 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 710, 'gbm_criterion': 'mse', 'gbm_max_depth': 3, 'gbm_min_samples_split': 0.3454156420537172}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:46,923]\u001b[0m Trial 8 finished with value: 0.6256360598465861 and parameters: {'classifier': 'RF', 'rf_n_estimators': 884, 'rf_criterion': 'gini', 'rf_max_depth': 4, 'rf_min_samples_split': 0.9711603957135369}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-05-20 13:53:46,998]\u001b[0m Trial 9 finished with value: 0.9120148856990963 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 8.106392638377931}. Best is trial 3 with value: 0.9623110807321332.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:47,479]\u001b[0m Trial 10 finished with value: 0.9648173463962938 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 155, 'gbm_criterion': 'mse', 'gbm_max_depth': 1, 'gbm_min_samples_split': 0.015717696388715535}. Best is trial 10 with value: 0.9648173463962938.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:47,857]\u001b[0m Trial 11 finished with value: 0.9598048150679729 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 126, 'gbm_criterion': 'mse', 'gbm_max_depth': 1, 'gbm_min_samples_split': 0.0505080915385263}. Best is trial 10 with value: 0.9648173463962938.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:48,471]\u001b[0m Trial 12 finished with value: 0.9698298777246146 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 202, 'gbm_criterion': 'mse', 'gbm_max_depth': 1, 'gbm_min_samples_split': 0.027893054655714566}. Best is trial 12 with value: 0.9698298777246146.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:48,802]\u001b[0m Trial 13 finished with value: 0.9572795625427205 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 110, 'gbm_criterion': 'friedman_mse', 'gbm_max_depth': 1, 'gbm_min_samples_split': 0.9426145187874346}. Best is trial 12 with value: 0.9698298777246146.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:49,802]\u001b[0m Trial 14 finished with value: 0.9647983595352017 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 338, 'gbm_criterion': 'mse', 'gbm_max_depth': 1, 'gbm_min_samples_split': 0.044391377955662156}. Best is trial 12 with value: 0.9698298777246146.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:50,977]\u001b[0m Trial 15 finished with value: 0.9698488645857067 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 301, 'gbm_criterion': 'mse', 'gbm_max_depth': 2, 'gbm_min_samples_split': 0.7450851430645121}. Best is trial 15 with value: 0.9698488645857067.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:53,050]\u001b[0m Trial 16 finished with value: 0.9673425989215462 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 403, 'gbm_criterion': 'friedman_mse', 'gbm_max_depth': 2, 'gbm_min_samples_split': 0.7395765640335117}. Best is trial 15 with value: 0.9698488645857067.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:53:59,471]\u001b[0m Trial 17 finished with value: 0.9673236120604543 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 989, 'gbm_criterion': 'mse', 'gbm_max_depth': 4, 'gbm_min_samples_split': 0.6793586178991271}. Best is trial 15 with value: 0.9698488645857067.\u001b[0m\n",
      "\u001b[32m[I 2021-05-20 13:54:00,379]\u001b[0m Trial 18 finished with value: 0.9647983595352017 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 258, 'gbm_criterion': 'mse', 'gbm_max_depth': 2, 'gbm_min_samples_split': 0.975701213826428}. Best is trial 15 with value: 0.9698488645857067.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-20 13:54:03,419]\u001b[0m Trial 19 finished with value: 0.9623300675932255 and parameters: {'classifier': 'GBM', 'gbm_n_estimators': 567, 'gbm_criterion': 'mse', 'gbm_max_depth': 3, 'gbm_min_samples_split': 0.6447938949231241}. Best is trial 15 with value: 0.9698488645857067.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    # we do not need the below line, \n",
    "    # tpe is the default search\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    ")\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'GBM',\n",
       " 'gbm_n_estimators': 301,\n",
       " 'gbm_criterion': 'mse',\n",
       " 'gbm_max_depth': 2,\n",
       " 'gbm_min_samples_split': 0.7450851430645121}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698488645857067"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_classifier</th>\n",
       "      <th>params_gbm_criterion</th>\n",
       "      <th>params_gbm_max_depth</th>\n",
       "      <th>params_gbm_min_samples_split</th>\n",
       "      <th>params_gbm_n_estimators</th>\n",
       "      <th>params_logit_c</th>\n",
       "      <th>params_logit_penalty</th>\n",
       "      <th>params_rf_criterion</th>\n",
       "      <th>params_rf_max_depth</th>\n",
       "      <th>params_rf_min_samples_split</th>\n",
       "      <th>params_rf_n_estimators</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.912015</td>\n",
       "      <td>2021-05-20 13:53:31.360491</td>\n",
       "      <td>2021-05-20 13:53:31.433543</td>\n",
       "      <td>0 days 00:00:00.073052</td>\n",
       "      <td>logit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.072657</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.912015</td>\n",
       "      <td>2021-05-20 13:53:31.434544</td>\n",
       "      <td>2021-05-20 13:53:31.529611</td>\n",
       "      <td>0 days 00:00:00.095067</td>\n",
       "      <td>logit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.331768</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.912015</td>\n",
       "      <td>2021-05-20 13:53:31.530710</td>\n",
       "      <td>2021-05-20 13:53:31.606316</td>\n",
       "      <td>0 days 00:00:00.075606</td>\n",
       "      <td>logit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.617337</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.962311</td>\n",
       "      <td>2021-05-20 13:53:31.608011</td>\n",
       "      <td>2021-05-20 13:53:33.443316</td>\n",
       "      <td>0 days 00:00:01.835305</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>356.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>2021-05-20 13:53:33.447319</td>\n",
       "      <td>2021-05-20 13:53:34.204855</td>\n",
       "      <td>0 days 00:00:00.757536</td>\n",
       "      <td>RF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.753918</td>\n",
       "      <td>145.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.917122</td>\n",
       "      <td>2021-05-20 13:53:34.206857</td>\n",
       "      <td>2021-05-20 13:53:35.447736</td>\n",
       "      <td>0 days 00:00:01.240879</td>\n",
       "      <td>RF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.592372</td>\n",
       "      <td>267.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>2021-05-20 13:53:35.449738</td>\n",
       "      <td>2021-05-20 13:53:38.711194</td>\n",
       "      <td>0 days 00:00:03.261456</td>\n",
       "      <td>RF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.894730</td>\n",
       "      <td>798.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.947292</td>\n",
       "      <td>2021-05-20 13:53:38.712696</td>\n",
       "      <td>2021-05-20 13:53:42.948934</td>\n",
       "      <td>0 days 00:00:04.236238</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.345416</td>\n",
       "      <td>710.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>2021-05-20 13:53:42.949917</td>\n",
       "      <td>2021-05-20 13:53:46.923493</td>\n",
       "      <td>0 days 00:00:03.973576</td>\n",
       "      <td>RF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.971160</td>\n",
       "      <td>884.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.912015</td>\n",
       "      <td>2021-05-20 13:53:46.924494</td>\n",
       "      <td>2021-05-20 13:53:46.998348</td>\n",
       "      <td>0 days 00:00:00.073854</td>\n",
       "      <td>logit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.106393</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.964817</td>\n",
       "      <td>2021-05-20 13:53:46.999349</td>\n",
       "      <td>2021-05-20 13:53:47.479689</td>\n",
       "      <td>0 days 00:00:00.480340</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.959805</td>\n",
       "      <td>2021-05-20 13:53:47.481128</td>\n",
       "      <td>2021-05-20 13:53:47.857398</td>\n",
       "      <td>0 days 00:00:00.376270</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050508</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.969830</td>\n",
       "      <td>2021-05-20 13:53:47.858491</td>\n",
       "      <td>2021-05-20 13:53:48.470927</td>\n",
       "      <td>0 days 00:00:00.612436</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>2021-05-20 13:53:48.472928</td>\n",
       "      <td>2021-05-20 13:53:48.802770</td>\n",
       "      <td>0 days 00:00:00.329842</td>\n",
       "      <td>GBM</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942615</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>2021-05-20 13:53:48.803790</td>\n",
       "      <td>2021-05-20 13:53:49.802499</td>\n",
       "      <td>0 days 00:00:00.998709</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044391</td>\n",
       "      <td>338.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.969849</td>\n",
       "      <td>2021-05-20 13:53:49.803482</td>\n",
       "      <td>2021-05-20 13:53:50.977314</td>\n",
       "      <td>0 days 00:00:01.173832</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.745085</td>\n",
       "      <td>301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.967343</td>\n",
       "      <td>2021-05-20 13:53:50.978532</td>\n",
       "      <td>2021-05-20 13:53:53.049087</td>\n",
       "      <td>0 days 00:00:02.070555</td>\n",
       "      <td>GBM</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.739577</td>\n",
       "      <td>403.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.967324</td>\n",
       "      <td>2021-05-20 13:53:53.053091</td>\n",
       "      <td>2021-05-20 13:53:59.471994</td>\n",
       "      <td>0 days 00:00:06.418903</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.679359</td>\n",
       "      <td>989.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>2021-05-20 13:53:59.472993</td>\n",
       "      <td>2021-05-20 13:54:00.378635</td>\n",
       "      <td>0 days 00:00:00.905642</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.975701</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.962330</td>\n",
       "      <td>2021-05-20 13:54:00.380637</td>\n",
       "      <td>2021-05-20 13:54:03.418441</td>\n",
       "      <td>0 days 00:00:03.037804</td>\n",
       "      <td>GBM</td>\n",
       "      <td>mse</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.644794</td>\n",
       "      <td>567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.912015 2021-05-20 13:53:31.360491 2021-05-20 13:53:31.433543   \n",
       "1        1  0.912015 2021-05-20 13:53:31.434544 2021-05-20 13:53:31.529611   \n",
       "2        2  0.912015 2021-05-20 13:53:31.530710 2021-05-20 13:53:31.606316   \n",
       "3        3  0.962311 2021-05-20 13:53:31.608011 2021-05-20 13:53:33.443316   \n",
       "4        4  0.625636 2021-05-20 13:53:33.447319 2021-05-20 13:53:34.204855   \n",
       "5        5  0.917122 2021-05-20 13:53:34.206857 2021-05-20 13:53:35.447736   \n",
       "6        6  0.625636 2021-05-20 13:53:35.449738 2021-05-20 13:53:38.711194   \n",
       "7        7  0.947292 2021-05-20 13:53:38.712696 2021-05-20 13:53:42.948934   \n",
       "8        8  0.625636 2021-05-20 13:53:42.949917 2021-05-20 13:53:46.923493   \n",
       "9        9  0.912015 2021-05-20 13:53:46.924494 2021-05-20 13:53:46.998348   \n",
       "10      10  0.964817 2021-05-20 13:53:46.999349 2021-05-20 13:53:47.479689   \n",
       "11      11  0.959805 2021-05-20 13:53:47.481128 2021-05-20 13:53:47.857398   \n",
       "12      12  0.969830 2021-05-20 13:53:47.858491 2021-05-20 13:53:48.470927   \n",
       "13      13  0.957280 2021-05-20 13:53:48.472928 2021-05-20 13:53:48.802770   \n",
       "14      14  0.964798 2021-05-20 13:53:48.803790 2021-05-20 13:53:49.802499   \n",
       "15      15  0.969849 2021-05-20 13:53:49.803482 2021-05-20 13:53:50.977314   \n",
       "16      16  0.967343 2021-05-20 13:53:50.978532 2021-05-20 13:53:53.049087   \n",
       "17      17  0.967324 2021-05-20 13:53:53.053091 2021-05-20 13:53:59.471994   \n",
       "18      18  0.964798 2021-05-20 13:53:59.472993 2021-05-20 13:54:00.378635   \n",
       "19      19  0.962330 2021-05-20 13:54:00.380637 2021-05-20 13:54:03.418441   \n",
       "\n",
       "                 duration params_classifier params_gbm_criterion  \\\n",
       "0  0 days 00:00:00.073052             logit                  NaN   \n",
       "1  0 days 00:00:00.095067             logit                  NaN   \n",
       "2  0 days 00:00:00.075606             logit                  NaN   \n",
       "3  0 days 00:00:01.835305               GBM                  mse   \n",
       "4  0 days 00:00:00.757536                RF                  NaN   \n",
       "5  0 days 00:00:01.240879                RF                  NaN   \n",
       "6  0 days 00:00:03.261456                RF                  NaN   \n",
       "7  0 days 00:00:04.236238               GBM                  mse   \n",
       "8  0 days 00:00:03.973576                RF                  NaN   \n",
       "9  0 days 00:00:00.073854             logit                  NaN   \n",
       "10 0 days 00:00:00.480340               GBM                  mse   \n",
       "11 0 days 00:00:00.376270               GBM                  mse   \n",
       "12 0 days 00:00:00.612436               GBM                  mse   \n",
       "13 0 days 00:00:00.329842               GBM         friedman_mse   \n",
       "14 0 days 00:00:00.998709               GBM                  mse   \n",
       "15 0 days 00:00:01.173832               GBM                  mse   \n",
       "16 0 days 00:00:02.070555               GBM         friedman_mse   \n",
       "17 0 days 00:00:06.418903               GBM                  mse   \n",
       "18 0 days 00:00:00.905642               GBM                  mse   \n",
       "19 0 days 00:00:03.037804               GBM                  mse   \n",
       "\n",
       "    params_gbm_max_depth  params_gbm_min_samples_split  \\\n",
       "0                    NaN                           NaN   \n",
       "1                    NaN                           NaN   \n",
       "2                    NaN                           NaN   \n",
       "3                    2.0                      0.260728   \n",
       "4                    NaN                           NaN   \n",
       "5                    NaN                           NaN   \n",
       "6                    NaN                           NaN   \n",
       "7                    3.0                      0.345416   \n",
       "8                    NaN                           NaN   \n",
       "9                    NaN                           NaN   \n",
       "10                   1.0                      0.015718   \n",
       "11                   1.0                      0.050508   \n",
       "12                   1.0                      0.027893   \n",
       "13                   1.0                      0.942615   \n",
       "14                   1.0                      0.044391   \n",
       "15                   2.0                      0.745085   \n",
       "16                   2.0                      0.739577   \n",
       "17                   4.0                      0.679359   \n",
       "18                   2.0                      0.975701   \n",
       "19                   3.0                      0.644794   \n",
       "\n",
       "    params_gbm_n_estimators  params_logit_c params_logit_penalty  \\\n",
       "0                       NaN        6.072657                   l1   \n",
       "1                       NaN        7.331768                   l1   \n",
       "2                       NaN        7.617337                   l1   \n",
       "3                     356.0             NaN                  NaN   \n",
       "4                       NaN             NaN                  NaN   \n",
       "5                       NaN             NaN                  NaN   \n",
       "6                       NaN             NaN                  NaN   \n",
       "7                     710.0             NaN                  NaN   \n",
       "8                       NaN             NaN                  NaN   \n",
       "9                       NaN        8.106393                   l1   \n",
       "10                    155.0             NaN                  NaN   \n",
       "11                    126.0             NaN                  NaN   \n",
       "12                    202.0             NaN                  NaN   \n",
       "13                    110.0             NaN                  NaN   \n",
       "14                    338.0             NaN                  NaN   \n",
       "15                    301.0             NaN                  NaN   \n",
       "16                    403.0             NaN                  NaN   \n",
       "17                    989.0             NaN                  NaN   \n",
       "18                    258.0             NaN                  NaN   \n",
       "19                    567.0             NaN                  NaN   \n",
       "\n",
       "   params_rf_criterion  params_rf_max_depth  params_rf_min_samples_split  \\\n",
       "0                  NaN                  NaN                          NaN   \n",
       "1                  NaN                  NaN                          NaN   \n",
       "2                  NaN                  NaN                          NaN   \n",
       "3                  NaN                  NaN                          NaN   \n",
       "4                 gini                  3.0                     0.753918   \n",
       "5                 gini                  1.0                     0.592372   \n",
       "6              entropy                  4.0                     0.894730   \n",
       "7                  NaN                  NaN                          NaN   \n",
       "8                 gini                  4.0                     0.971160   \n",
       "9                  NaN                  NaN                          NaN   \n",
       "10                 NaN                  NaN                          NaN   \n",
       "11                 NaN                  NaN                          NaN   \n",
       "12                 NaN                  NaN                          NaN   \n",
       "13                 NaN                  NaN                          NaN   \n",
       "14                 NaN                  NaN                          NaN   \n",
       "15                 NaN                  NaN                          NaN   \n",
       "16                 NaN                  NaN                          NaN   \n",
       "17                 NaN                  NaN                          NaN   \n",
       "18                 NaN                  NaN                          NaN   \n",
       "19                 NaN                  NaN                          NaN   \n",
       "\n",
       "    params_rf_n_estimators     state  \n",
       "0                      NaN  COMPLETE  \n",
       "1                      NaN  COMPLETE  \n",
       "2                      NaN  COMPLETE  \n",
       "3                      NaN  COMPLETE  \n",
       "4                    145.0  COMPLETE  \n",
       "5                    267.0  COMPLETE  \n",
       "6                    798.0  COMPLETE  \n",
       "7                      NaN  COMPLETE  \n",
       "8                    884.0  COMPLETE  \n",
       "9                      NaN  COMPLETE  \n",
       "10                     NaN  COMPLETE  \n",
       "11                     NaN  COMPLETE  \n",
       "12                     NaN  COMPLETE  \n",
       "13                     NaN  COMPLETE  \n",
       "14                     NaN  COMPLETE  \n",
       "15                     NaN  COMPLETE  \n",
       "16                     NaN  COMPLETE  \n",
       "17                     NaN  COMPLETE  \n",
       "18                     NaN  COMPLETE  \n",
       "19                     NaN  COMPLETE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBM      12\n",
       "logit     4\n",
       "RF        4\n",
       "Name: params_classifier, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = study.trials_dataframe()\n",
    "\n",
    "results['params_classifier'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search quickly realised that GBM returned the best performance, so explored the hyperparameter space for that model more than for the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.963148</td>\n",
       "      <td>0.006261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.698508</td>\n",
       "      <td>0.145743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>0.912015</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean       std\n",
       "params_classifier                    \n",
       "GBM                0.963148  0.006261\n",
       "RF                 0.698508  0.145743\n",
       "logit              0.912015  0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(['params_classifier'])['value'].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmX0lEQVR4nO3de5wddX3/8dc7u9nNZZOQZBcICSRAg1x+KNA0KihSUQzUGqQXgzdUKmKFeqm2WH0g0tpaq1VbqYqVeqmAiAWjxSIKVKuoWSCgBAMhgiSAZ5MAu0nYs9ndz++PmV2Gk7ObE7Jzzuzu+/l4nMfO5TtzPjt7dj5nvt/5fkcRgZmZWaUpjQ7AzMyKyQnCzMyqcoIwM7OqnCDMzKwqJwgzM6vKCcLMzKpygjCbxCS9SdL/NToOKyYnCCssSa+V1Clpu6RHJX1X0osaHddkJelWSX/W6DisfpwgrJAkvQf4FPD3wAHAIcC/ASsbGNYzSGpudAxmeXKCsMKRNAe4FHhHRPxXROyIiF0R8e2IeF9aplXSpyQ9kr4+Jak1XXeKpE2S/lJSKb36eHO67vmSHpPUlHm/V0u6O52eIukiSQ9I2irpGknz0nVLJIWkcyX9BrhZUpOkT0jaIunXki5IyzQP/S6SvpjGsFnS3w2991D1jqSPS3o83f70TFzzJP1H+vs9Lun6zLpXSlor6QlJP5H03FGOZ0j6C0kb0zj/SVLV/31JJ0paI+nJ9OeJ6fKPAC8GPpNe0X1m7/+yNt44QVgRvRCYBlw3SpkPAC8AjgOeBywHPphZfyAwB1gInAtcJmluRPwM2AG8NFP2tcCV6fSFwJnAS4CDgMeByyre+yXAUcArgLcCp6dxnJBum/UloB/4HeB44DQgW03zfGA90A58DPiiJKXrvgrMAI4B9gc+CSDpeOAK4G3AfODzwOqhBDmCVwPL0hhXAm+pLJAmwv8G/iXd7z8D/y1pfkR8APgRcEFEtEXEBaO8l00UEeGXX4V6Aa8DHttDmQeAMzLzrwAeTKdPAZ4CmjPrS8AL0um/A65Ip2eRJIzF6fy9wKmZ7RYAu4BmYAkQwGGZ9TcDb8vMvywt00xSNVYGpmfWnw3ckk6/CdiQWTcj3fbA9H0HgblVfvfPAn9bsWw98JIRjlUAKzLzfw78IBPD/6XTbwB+XrHtbcCb0ulbgT9r9OfDr/q9XIdqRbQVaJfUHBH9I5Q5CHgoM/9Qumx4HxXb7gTa0ukrgZ9IejtwFnBHRAztazFwnaTBzLYDJCf7IQ9XxPHwCOsWA1OBR5++KGBKRZnHhiYiYmdarg2YB2yLiMfZ3WLgHEkXZpa18Mzfv1L2PSuPVfZ3eahi2UMkV2E2CbmKyYroNpJv3meOUuYRkhPlkEPSZXsUEetITnyn88zqJUhOpKdHxH6Z17SI2JzdRWb6UWBRZv7gin2VgfbMvmZHxDE1hPkwME/SfiOs+0hFjDMi4qpR9peNa6RjVXlMh8oO/e4e+nmScYKwwomIJ4GLSdoNzpQ0Q9JUSadL+lha7Crgg5I6JLWn5f9zL97mSuCdwMnANzLLPwd8RNJigHT/o905dQ3wTkkL05P5X2d+j0eB7wGfkDQ7bQA/XNJL9hRcuu13gX+TNDf9/U9OV38BOD9tcJekmZL+QNKsUXb5vnQ/B6e/99erlLkBOCK9vbhZ0muAo4HvpOt/Cxy2p9ht4nCCsEKKiE8A7yFpeO4i+dZ8AXB9WuTvgE7gbuAXwB3pslpdRdLYfHNEbMks/zSwGviepB7gpyQNySP5AkkSuBu4k+Qk209SLQXwRpLqn3UkDd7XkrQv1OINJO0fvyJpQ3kXQER0kjSOfybd5waStoTRfAu4HVhL0hD9xcoCEbEVeCXwlyTVfH8FvDJzfD4N/HF6R9W/1Pg72DimCF81mo2V9DbVz0VEZVVNw0gKYGlEbGh0LDa++ArCbB9Imi7pjLRKZiHwIUa/Pdds3HCCMNs3Aj5MUtVzJ8ltshc3NCKzMeIqJjMzq8pXEGZmVtWE6SjX3t4eS5YsaXQYZmbjyu23374lIjqqrZswCWLJkiV0dnY2Ogwzs3FFUmXv+WGuYjIzs6qcIMzMrConCDMzq8oJwszMqnKCMDOzqpwgzMysKicIMzOrasL0gzAzK7pdA4Ns29HHlu1ltmzvY0tPmS3by+zsG9it7IiDIFUZHunAOdN57fMPGdtgcYIws0mur3+Q3v4qJ+hqZ+gqy4JgR9/A8Ml+6OTf1VNm646+Zyx/fOeuMYn56SfYJo47eD8nCDOzWvTuGnjGiXrL9nLmRN1H1/anl3X3jvTY833T1tpMe1sL7W2tHN7RxvMPm8f8ma20z2qlI13e3pbMz2xpQpVn/QJwgjCzmuzs62dLT3Jy3TpURZJOl/sHn/V+RxpQOqp8Xa9WNoAd5f5nVNv0lKuf9GdNa6YjPTE/54BZnHR4O+1trcxsbapavtpJu9ppfEZL0/DJfv7MFjpmtTJtavV9jidOEGbjVETQ3ds/4gm6+sm0+kl3+9AJdqhaZHuZrp4+tu4Y+qbdx1O7dq+GAZg9rZnpLft2MlTV0+7uVSlJ2d3NSL+tH3PQbNrbWumY1Tr87T174p4IJ+16coIwK5CI4MmndrFle5lSzzMbMrdkvrVv6SmzZUcfffvwzX0kUwTzZj59gl18yAzmD51on3HSbWHezBZam33SnaicIMxyNjgYPJGe9Lf0lOnaXk7rxfsyJ/7kW/rWHWV2Dez+Lb9pipg/s2X42/Dv7N82XFUyv62FGSN+g69SRVLlK3hSX57sa+6MFpqmFK8+3OrPCcJsH0QEv9j8JBu7diTVMumJfstwEiizbUcf/YO7n/SnNmn423hHWytHHTib9llPf1PvSJNBe1sr+02fyhSftK3OnCDMnoVfb9nB9Xdu5vq1m3lo687h5S1NU5JqmFmtHDhnGscunEP7rEy1TFo/3tHWyuzpzYW8c8VsSK4JQtIK4NNAE/DvEfHRivWLgSuADmAb8PqI2JSuGwB+kRb9TUS8Ks9YzfZky/Yy37nrEa5b+wh3PfwEEpx4+Hze8fu/wwmHzKVjViuzp/mkbxNHbglCUhNwGfByYBOwRtLqiFiXKfZx4CsR8WVJLwX+AXhDuu6piDgur/jMarGzr5+b1v2W6+7czI/u38LAYHD0gtn8zRlH8qrnLeTAOdMaHaJZbvK8glgObIiIjQCSrgZWAtkEcTTwnnT6FuD6HOMxq0n/wCA/fmAr19+5mRvveYydfQMs3G865518GGcet5DnHDir0SGa1UWeCWIh8HBmfhPw/IoydwFnkVRDvRqYJWl+RGwFpknqBPqBj0bE9TnGapPcUGPzdXdu5tt3PcqW7WVmT2tm5XELOfO4g/i9JfPcSGyTTqMbqd8LfEbSm4AfApuBod44iyNis6TDgJsl/SIiHshuLOk84DyAQw4Z+3FIbOKLCL5y20N8+bYH2di1g5amKZx61P6sPG4hv39kh+/xt0ktzwSxGTg4M78oXTYsIh4huYJAUhvwRxHxRLpuc/pzo6RbgeOBByq2vxy4HGDZsmUjDn5oNpLP3LyBT9x0H8sWz+W8sw7j9GMXMGf61EaHZVYIeSaINcBSSYeSJIZVwGuzBSS1A9siYhB4P8kdTUiaC+yMiHJa5iTgYznGapPQV3/6EJ+46T7OOn4hH/+T57kKyaxCbg8Mioh+4ALgRuBe4JqIuEfSpZKGblk9BVgv6T7gAOAj6fKjgE5Jd5E0Xn+04u4ns32y+q5HuPhbv+RlR+3PP/7xc50czKpQjDSU4jizbNmy6OzsbHQYNg7cur7En325kxMWz+Urb1nuAdxsUpN0e0Qsq7bOjxy1SeX2h7Zx/n/eznMOnMW/n7PMycFsFE4QNmn86rFu3vwfa1gwZzpffstyZk9zY7TZaJwgbFL4zdadvOGLP2dGSzNfPXc57W2tjQ7JrPCcIGzCK3X38vov/oxdA4N89dzlLJo7o9EhmY0LThA2oT25cxdvvOLnbNle5ktvXs7SAzxMhlmtnCBswnqqb4Bzv7yGjV07uPwNyzju4P0aHZLZuOIEYRPSroFB3v6127njN4/z6VXH8aKl7Y0OyWzcafRYTGZjbnAweO837uLW9V38w1nHcvqxCxodktm45CsIm1Aigku+fQ/fWvsIf73iSM5e7kEczZ4tJwibUD71/fv5ym0P8baTD+Ptpxze6HDMxjUnCJsw/uPHv+bTP7ifP122iItOP7LR4ZiNe04QNiFcd+cmPvztdbzimAP4+1cf6+dCm40BN1LbuNbXP8j31j3Ge79xNycePp9Przqe5iZ/7zEbC04QNm509ZT51WPd3PtoN/c+2sO9j3azobSd/sHguYvmcPkbPfie2VhygrDC2TUwyMauHWki6GZdmhC2bC8Plzlw9jSOWjCLlx65P0ctmM1Lj9yfma3+OJuNJf9HTQDrHunmse6nGh3GszY4CA9u3fGMq4K+gUEAWpqmsPSANk55TgdHHjiLoxfM5qgFs5k7s6XBUZtNfE4Q41zvrgHOvOzHwyfU8ay9rZWjFszixUuXcFSaCA7rmMlUtymYNYQTxDhX6i7TNzDIO09dykuP3L/R4TxrB+03nY5ZHoLbrEicIMa5Uk8vAMcfsh/P82B0ZjaGfO0+zpV6kobb/WdNa3AkZjbR5JogJK2QtF7SBkkXVVm/WNIPJN0t6VZJizLrzpF0f/o6J884x7NSd3IFsf9sV8+Y2djKLUFIagIuA04HjgbOlnR0RbGPA1+JiOcClwL/kG47D/gQ8HxgOfAhSXPzinU8K/WUaZ4i5s3wXT1mNrbyvIJYDmyIiI0R0QdcDaysKHM0cHM6fUtm/SuAmyJiW0Q8DtwErMgx1nGr1FOmva2VKVM8tISZja08E8RC4OHM/KZ0WdZdwFnp9KuBWZLm17gtks6T1Cmps6ura8wCH0+6esquXjKzXDS6kfq9wEsk3Qm8BNgMDNS6cURcHhHLImJZR0dHXjEWWqmnzP6+PdTMcpBngtgMHJyZX5QuGxYRj0TEWRFxPPCBdNkTtWxria6eXjp8B5OZ5SDPBLEGWCrpUEktwCpgdbaApHZJQzG8H7ginb4ROE3S3LRx+rR0mWX0DwyydUefryDMLBe5JYiI6AcuIDmx3wtcExH3SLpU0qvSYqcA6yXdBxwAfCTddhvwtyRJZg1wabrMMrZs7yPCt7iaWT5y7UkdETcAN1QsuzgzfS1w7QjbXsHTVxRWxVAvaneSM7M8NLqR2vZBqXuoF7WvIMxs7DlBjGPDw2y4isnMcuAEMY4NVTHNn+kEYWZjzwliHCv1lJk3s4WWZv8ZzWzs+cwyjpW63UnOzPLjBDGOJZ3knCDMLB9OEONYMsyGb3E1s3w4QYxTg4PhgfrMLFdOEOPU4zv76B8Mt0GYWW6cIMapru1+1KiZ5csJYpwa7kXtKiYzy4kTxDg13IvaVUxmlhMniHHKA/WZWd6cIMapUneZWa3NTG9panQoZjZBOUGMU109ZTrc/mBmOXKCGKdKPb1ufzCzXDlBjFPuRW1meXOCGIciglJ32eMwmVmunCDGoe3lfp7aNeAqJjPLlRPEOOQnyZlZPeSaICStkLRe0gZJF1VZf4ikWyTdKeluSWeky5dIekrS2vT1uTzjHG+efha12yDMLD/Nee1YUhNwGfByYBOwRtLqiFiXKfZB4JqI+Kyko4EbgCXpugci4ri84hvPnu4k5ysIM8tPnlcQy4ENEbExIvqAq4GVFWUCmJ1OzwEeyTGeCaOrx1cQZpa/PBPEQuDhzPymdFnWJcDrJW0iuXq4MLPu0LTq6X8lvbjaG0g6T1KnpM6urq4xDL3YSj1lWpqnMHt6bheAZmYNb6Q+G/hSRCwCzgC+KmkK8ChwSEQcD7wHuFLS7MqNI+LyiFgWEcs6OjrqGngjdfUkz6KW1OhQzGwCyzNBbAYOzswvSpdlnQtcAxARtwHTgPaIKEfE1nT57cADwBE5xjquuBe1mdVDngliDbBU0qGSWoBVwOqKMr8BTgWQdBRJguiS1JE2ciPpMGApsDHHWMeVUrd7UZtZ/nJLEBHRD1wA3AjcS3K30j2SLpX0qrTYXwJvlXQXcBXwpogI4GTgbklrgWuB8yNiW16xjjclP4vazOog11bOiLiBpPE5u+zizPQ64KQq230T+GaesY1XvbsGePKpXa5iMrPcNbqR2vaSb3E1s3pxghhnhobZ8LMgzCxvThDjTJd7UZtZnThBjDMlVzGZWZ3sMUFI+sO085oVQKm7zBTBvJktjQ7FzCa4Wk78rwHul/QxSUfmHZCNrtTTS3tbK01T3IvazPK1xwQREa8HjifpzfwlSbelYyDNyj062437QJhZvdRUdRQR3SQd1q4GFgCvBu6QdOGoG9qYcy9qM6uXWtogXiXpOuBWYCqwPCJOB55H0hPa6qiUDtRnZpa3WnpS/xHwyYj4YXZhROyUdG4+YVk1/QODbN3hBGFm9VFLgriEZPhtACRNBw6IiAcj4gd5BWa727qjjwjomO0qJjPLXy1tEN8ABjPzA+kyq7Onh9nwFYSZ5a+WBNGcPjIUgHTaN+E3gJ9FbWb1VEuC6MoMz42klcCW/EKykZS60ysIVzGZWR3U0gZxPvA1SZ8BRPKc6TfmGpVVNTxQX5uvIMwsf3tMEBHxAPACSW3p/Pbco7KqSj29zJ0xlZZmj3xiZvmr6YFBkv4AOAaYJiVDPETEpTnGZVW4k5yZ1VMtHeU+RzIe04UkVUx/AizOOS6rwsNsmFk91VJXcWJEvBF4PCI+DLwQOCLfsKyarp4yHb6DyczqpJYE0Zv+3CnpIGAXyXhMVkcR4QRhZnVVS4L4tqT9gH8C7gAeBK6sZeeSVkhaL2mDpIuqrD9E0i2S7pR0t6QzMuven263XtIravptJrAndu6ib2DQbRBmVjejNlKnDwr6QUQ8AXxT0neAaRHx5J52LKkJuAx4ObAJWCNpdUSsyxT7IHBNRHxW0tHADcCSdHoVScP4QcD3JR0REQN7/ytODCX3ojazOhv1CiIiBklO8kPz5VqSQ2o5sCEiNqa9r68GVla+BTA7nZ4DPJJOrwSuTt/v18CGdH+TlntRm1m91VLF9ANJf6Sh+1trt5CkU92QTemyrEuA10vaRHL1MPR8iVq2JX1wUaekzq6urr0Mb3xxL2ozq7daEsTbSAbnK0vqltQjqXuM3v9s4EsRsQg4A/jq3jz/OiIuj4hlEbGso6NjjEIqJlcxmVm91dKT+tk+WnQzcHBmflG6LOtcYEX6PrdJmga017jtpFLq6WVmSxMzW2vq22hmts/2eLaRdHK15ZUPEKpiDbBU0qEkJ/dVwGsryvwGOJXkWddHAdOALmA1cKWkfyZppF4K/HxPsU5kXT1lVy+ZWV3V8nX0fZnpaSSNxbcDLx1to4jol3QBcCPQBFwREfdIuhTojIjVJI8s/YKkd5M0WL8pIgK4R9I1wDqgH3jHZL6DCZIqJveBMLN6qqWK6Q+z85IOBj5Vy84j4gaSxufssosz0+uAk0bY9iPAR2p5n8mgq6fMMQfN3nNBM7Mx8myGBd0EHDXWgdjoSt297iRnZnVVSxvEv5JU/0CSUI4j6VFtdbKj3M+OvgEP1GdmdVVLG0RnZrofuCoifpxTPFaFb3E1s0aoJUFcC/QONRJLapI0IyJ25huaDSl1D/WidhWTmdVPTT2pgemZ+enA9/MJx6oZvoJwFZOZ1VEtCWJa9jGj6fSM/EKySq5iMrNGqCVB7JB0wtCMpN8FnsovJKtU6umlpWkKc6ZPbXQoZjaJ1NIG8S7gG5IeIXnk6IEkjyC1OunqTjrJ7f14iWZmz14tHeXWSDoSeE66aH1E7Mo3LMtyL2oza4Q9VjFJegcwMyJ+GRG/BNok/Xn+odmQUk+v2x/MrO5qaYN4a/pEOQAi4nHgrblFZLsp9ZR9B5OZ1V0tCaIp+7Cg9FGiLfmFZFnl/gGe2LnLfSDMrO5qaaT+H+Drkj6fzr8N+G5+IVlWl29xNbMGqSVB/DVwHnB+On83yZ1MVgdd7iRnZg2yxyqmiBgEfgY8SPIsiJcC9+Yblg15upOcq5jMrL5GvIKQdATJM6PPBrYAXweIiN+vT2gG7kVtZo0zWhXTr4AfAa+MiA0A6ZPfrI66unuZIpjf5gRhZvU1WhXTWcCjwC2SviDpVJKe1FZHpZ4y89taaZriQ29m9TVigoiI6yNiFXAkcAvJkBv7S/qspNPqFN+kV+opu3rJzBqilkbqHRFxZfps6kXAnSR3Nu2RpBWS1kvaIOmiKus/KWlt+rpP0hOZdQOZdatr/5UmFveiNrNGqeU212FpL+rL09eo0g51lwEvJ3mO9RpJqyNiXWZ/786UvxA4PrOLpyLiuL2JbyIqdZc5ZsGcRodhZpNQLT2pn63lwIaI2BgRfcDVwMpRyp8NXJVjPOPOwGCwZbsH6jOzxsgzQSwEHs7Mb0qX7UbSYuBQ4ObM4mmSOiX9VNKZI2x3Xlqms6ura4zCLo6tO8oMhjvJmVlj5Jkg9sYq4Nqh516nFkfEMuC1wKckHV65UURcHhHLImJZR0dHvWKtm1K3+0CYWePkmSA2Awdn5hely6pZRUX1UkRsTn9uBG7lme0Tk8LQMBsd7kVtZg2QZ4JYAyyVdKikFpIksNvdSOnDiOYCt2WWzZXUmk63AycB6yq3nehKPb2AryDMrDH26i6mvRER/ZIuAG4EmoArIuIeSZcCnRExlCxWAVdHRGQ2Pwr4vKRBkiT20ezdT5PFUBWTG6nNrBFySxAAEXEDcEPFsosr5i+pst1PgGPzjG08KPWUmTN9KtOmNjU6FDObhIrSSG1VdLkXtZk1kBNEgZV6en2Lq5k1jBNEgSXjMPkOJjNrDCeIgooID9RnZg3lBFFQ3U/109c/6DuYzKxhnCAKargPxGxXMZlZYzhBFJQfNWpmjeYEUVDuRW1mjeYEUVDDA/W5isnMGsQJoqBKPWWmT21iZot7UZtZYzhBFFSpp8z+s1uR1OhQzGyScoIoqFK3n0VtZo3lBFFQXe5FbWYN5gRRUKUeP4vazBrLCaKAdvb1s73c74H6zKyhnCAKqGu4k5yrmMyscZwgCsi9qM2sCJwgCujpTnJOEGbWOE4QBfT0MBuuYjKzxnGCKKBST5mpTWLujKmNDsXMJrFcE4SkFZLWS9og6aIq6z8paW36uk/SE5l150i6P32dk2ecRVPqLtPR5l7UZtZYzXntWFITcBnwcmATsEbS6ohYN1QmIt6dKX8hcHw6PQ/4ELAMCOD2dNvH84q3SEo9vXR4kD4za7A8ryCWAxsiYmNE9AFXAytHKX82cFU6/QrgpojYliaFm4AVOcZaKF1+1KiZFUCeCWIh8HBmflO6bDeSFgOHAjfvzbaSzpPUKamzq6trTIIuAj+L2syKoCiN1KuAayNiYG82iojLI2JZRCzr6OjIKbT66usfZNuOPg+zYWYNl2eC2AwcnJlflC6rZhVPVy/t7bYTypbt7kVtZsWQZ4JYAyyVdKikFpIksLqykKQjgbnAbZnFNwKnSZoraS5wWrpswnMvajMritzuYoqIfkkXkJzYm4ArIuIeSZcCnRExlCxWAVdHRGS23Sbpb0mSDMClEbEtr1iLpNSddpJzL2oza7DcEgRARNwA3FCx7OKK+UtG2PYK4IrcgiuokgfqM7OCKEojtaVKPWUkaG9raXQoZjbJOUEUTFdPL/NnttDc5D+NmTWWz0IF09VTpsPVS2ZWAE4QBeNOcmZWFE4QBVPqdoIws2JwgiiQwcFgy/ayb3E1s0JwgiiQbTv76B8M3+JqZoXgBFEgw48adRWTmRWAE0SBDD9q1FVMZlYAThAF4l7UZlYkThAF0pUmCA/1bWZF4ARRIKXuXmZNa2ba1KZGh2Jm5gRRJO4kZ2ZF4gRRIEmCcPuDmRWDE0SBlHp6fQeTmRWGE0RBRISH2TCzQnGCKIju3n7K/YOuYjKzwnCCKIihW1xdxWRmReEEURBDvajdB8LMisIJoiC63IvazAom1wQhaYWk9ZI2SLpohDJ/KmmdpHskXZlZPiBpbfpanWecRTA8UJ+rmMysIJrz2rGkJuAy4OXAJmCNpNURsS5TZinwfuCkiHhc0v6ZXTwVEcflFV/RlHp6mTZ1CrNac/uTmJntlTyvIJYDGyJiY0T0AVcDKyvKvBW4LCIeB4iIUo7xFNpQJzlJjQ7FzAzIN0EsBB7OzG9Kl2UdARwh6ceSfippRWbdNEmd6fIzq72BpPPSMp1dXV1jGny9uQ+EmRVNo+szmoGlwCnAIuCHko6NiCeAxRGxWdJhwM2SfhERD2Q3jojLgcsBli1bFnWNfIyVenp5zoGzGh2GmdmwPK8gNgMHZ+YXpcuyNgGrI2JXRPwauI8kYRARm9OfG4FbgeNzjLXhPA6TmRVNngliDbBU0qGSWoBVQOXdSNeTXD0gqZ2kymmjpLmSWjPLTwLWMUH17hqgp7fffSDMrFByq2KKiH5JFwA3Ak3AFRFxj6RLgc6IWJ2uO03SOmAAeF9EbJV0IvB5SYMkSeyj2bufJpqhW1ydIMysSHJtg4iIG4AbKpZdnJkO4D3pK1vmJ8CxecZWJMPPonaCMLMCcU/qAvCzqM2siJwgCqDUnV5BuBe1mRWIE0QBlHrKNE8R82a0NDoUM7NhThAFUOop097WypQp7kVtZsXhBFEAXT1lVy+ZWeE4QRRA0knOCcLMisUJogC6enrp8B1MZlYwjR6LqeGe2NnHn3zutobGsGV7n68gzKxwJn2CmDJFLD2graExHLlgNq987oKGxmBmVmnSJ4jZ06byb6/73UaHYWZWOG6DMDOzqpwgzMysKicIMzOrygnCzMyqcoIwM7OqnCDMzKwqJwgzM6vKCcLMzKpS8tTP8U9SF/DQPuyiHdgyRuHkwfHtG8e3bxzfvilyfIsjoqPaigmTIPaVpM6IWNboOEbi+PaN49s3jm/fFD2+kbiKyczMqnKCMDOzqpwgnnZ5owPYA8e3bxzfvnF8+6bo8VXlNggzM6vKVxBmZlaVE4SZmVU1qRKEpBWS1kvaIOmiKutbJX09Xf8zSUvqGNvBkm6RtE7SPZLeWaXMKZKelLQ2fV1cr/gyMTwo6Rfp+3dWWS9J/5Iew7slnVDH2J6TOTZrJXVLeldFmboeQ0lXSCpJ+mVm2TxJN0m6P/05d4Rtz0nL3C/pnDrG90+SfpX+/a6TtN8I2476Wcgxvkskbc78Dc8YYdtR/99zjO/rmdgelLR2hG1zP377LCImxQtoAh4ADgNagLuAoyvK/DnwuXR6FfD1Osa3ADghnZ4F3FclvlOA7zT4OD4ItI+y/gzgu4CAFwA/a+Df+zGSTkANO4bAycAJwC8zyz4GXJROXwT8Y5Xt5gEb059z0+m5dYrvNKA5nf7HavHV8lnIMb5LgPfW8Pcf9f89r/gq1n8CuLhRx29fX5PpCmI5sCEiNkZEH3A1sLKizErgy+n0tcCpklSP4CLi0Yi4I53uAe4FFtbjvcfYSuArkfgpsJ+kRjxw+1TggYjYl971+ywifghsq1ic/Zx9GTizyqavAG6KiG0R8ThwE7CiHvFFxPcioj+d/SmwaKzft1YjHL9a1PL/vs9Giy89d/wpcNVYv2+9TKYEsRB4ODO/id1PwMNl0n+QJ4H5dYkuI63aOh74WZXVL5R0l6TvSjqmvpEBEMD3JN0u6bwq62s5zvWwipH/MRt9DA+IiEfT6ceAA6qUKcpxfAvJFWE1e/os5OmCtArsihGq6Ipw/F4M/DYi7h9hfSOPX00mU4IYFyS1Ad8E3hUR3RWr7yCpMnke8K/A9XUOD+BFEXECcDrwDkknNyCGUUlqAV4FfKPK6iIcw2GR1DUU8l5zSR8A+oGvjVCkUZ+FzwKHA8cBj5JU4xTR2Yx+9VD4/6XJlCA2Awdn5hely6qWkdQMzAG21iW65D2nkiSHr0XEf1Wuj4juiNieTt8ATJXUXq/40vfdnP4sAdeRXMpn1XKc83Y6cEdE/LZyRRGOIfDboWq39GepSpmGHkdJbwJeCbwuTWK7qeGzkIuI+G1EDETEIPCFEd630cevGTgL+PpIZRp1/PbGZEoQa4Clkg5Nv2GuAlZXlFkNDN0t8sfAzSP9c4y1tL7yi8C9EfHPI5Q5cKhNRNJykr9fPRPYTEmzhqZJGjN/WVFsNfDG9G6mFwBPZqpT6mXEb26NPoap7OfsHOBbVcrcCJwmaW5ahXJauix3klYAfwW8KiJ2jlCmls9CXvFl27RePcL71vL/nqeXAb+KiE3VVjby+O2VRreS1/NFcofNfSR3N3wgXXYpyT8CwDSSaokNwM+Bw+oY24tIqhruBtamrzOA84Hz0zIXAPeQ3JHxU+DEOh+/w9L3viuNY+gYZmMUcFl6jH8BLKtzjDNJTvhzMssadgxJEtWjwC6SevBzSdq1fgDcD3wfmJeWXQb8e2bbt6SfxQ3Am+sY3waS+vuhz+HQnX0HATeM9lmoU3xfTT9bd5Oc9BdUxpfO7/b/Xo/40uVfGvrMZcrW/fjt68tDbZiZWVWTqYrJzMz2ghOEmZlV5QRhZmZVOUGYmVlVThBmZlaVE4RZFZK2pz+XSHrtGO/7byrmfzKW+zcbK04QZqNbAuxVgkh70Y7mGQkiIk7cy5jM6sIJwmx0HwVenI7Z/25JTenzEtakg8W9DYafM/EjSauBdemy69OB2O4ZGoxN0keB6en+vpYuG7paUbrvX6bPCXhNZt+3SrpWyXMavlavUYZtctvTNx2zye4ikmcPvBIgPdE/GRG/J6kV+LGk76VlTwD+X0T8Op1/S0RskzQdWCPpmxFxkaQLIuK4Ku91FskAdM8D2tNtfpiuOx44BngE+DFwEvB/Y/3LmmX5CsJs75xGMtbUWpLh2OcDS9N1P88kB4C/kDQ0pMfBmXIjeRFwVSQD0f0W+F/g9zL73hTJAHVrSaq+zHLlKwizvSPgwoh4xsB5kk4BdlTMvwx4YUTslHQryVhfz1Y5Mz2A/3etDnwFYTa6HpJHwA65EXh7OjQ7ko5IR+OsNAd4PE0OR5I8fnXIrqHtK/wIeE3aztFB8jjLn4/Jb2H2LPhbiNno7gYG0qqiLwGfJqneuSNtKO6i+iND/wc4X9K9wHqSaqYhlwN3S7ojIl6XWX4d8EKSET4D+KuIeCxNMGZ159FczcysKlcxmZlZVU4QZmZWlROEmZlV5QRhZmZVOUGYmVlVThBmZlaVE4SZmVX1/wHcySeMzvfyRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['value'].sort_values().reset_index(drop=True).plot()\n",
    "plt.title('Convergence plot')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html",
   "language": "python",
   "name": "html"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
