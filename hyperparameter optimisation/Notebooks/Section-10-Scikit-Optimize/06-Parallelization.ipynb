{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with Scikit-Optimize\n",
    "\n",
    "In this notebook, we will perform **Bayesian Optimization** with Gaussian Processes in Parallel, utilizing various CPUs, to speed up the search.\n",
    "\n",
    "This is useful to reduce search times. \n",
    "\n",
    "https://scikit-optimize.github.io/stable/auto_examples/parallel-optimization.html#example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from skopt import Optimizer # for the optimization\n",
    "from joblib import Parallel, delayed # for the parallelization\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "Scikit-optimize provides an utility function to create the range of values to examine for each hyperparameters. More details in [skopt.Space](https://scikit-optimize.github.io/stable/modules/generated/skopt.Space.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = [\n",
    "    Integer(10, 120, name=\"n_estimators\"),\n",
    "    Integer(1, 5, name=\"max_depth\"),\n",
    "    Real(0.0001, 0.1, prior='log-uniform', name='learning_rate'),\n",
    "    Real(0.001, 0.999, prior='log-uniform', name=\"min_samples_split\"),\n",
    "    Categorical(['deviance', 'exponential'], name=\"loss\"),\n",
    "]\n",
    "\n",
    "# Scikit-optimize parameter grid is a list\n",
    "type(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the gradient boosting classifier\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We design a function to maximize the accuracy, of a GBM,\n",
    "# with cross-validation\n",
    "\n",
    "# the decorator allows our objective function to receive the parameters as\n",
    "# keyword arguments. This is a requirement for scikit-optimize.\n",
    "\n",
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "    \n",
    "    # model with new parameters\n",
    "    gbm.set_params(**params)\n",
    "\n",
    "    # optimization function (hyperparam response function)\n",
    "    value = np.mean(\n",
    "        cross_val_score(\n",
    "            gbm, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=3,\n",
    "            n_jobs=-4,\n",
    "            scoring='accuracy')\n",
    "    )\n",
    "\n",
    "    # negate because we need to minimize\n",
    "    return -value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Optimizer\n",
    "\n",
    "optimizer = Optimizer(\n",
    "    dimensions = param_grid, # the hyperparameter space\n",
    "    base_estimator = \"GP\", # the surrogate\n",
    "    n_initial_points=10, # the number of points to evaluate f(x) to start of\n",
    "    acq_func='EI', # the acquisition function\n",
    "    random_state=0, \n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use 4 CPUs (n_points)\n",
    "# if we loop 10 times using 4 end points, we perform 40 searches in total\n",
    "\n",
    "for i in range(10):\n",
    "    x = optimizer.ask(n_points=4)  # x is a list of n_points points\n",
    "    y = Parallel(n_jobs=4)(delayed(objective)(v) for v in x)  # evaluate points in parallel\n",
    "    optimizer.tell(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[68, 4, 0.007381238832487747, 0.08704800719052391, 'exponential'],\n",
       " [118, 2, 0.00010113718979245275, 0.05725990689319986, 'deviance'],\n",
       " [17, 3, 0.00022221129238269847, 0.17371729808265857, 'exponential'],\n",
       " [42, 4, 0.000960176974739521, 0.6793527084375192, 'exponential'],\n",
       " [38, 5, 0.053126979002083165, 0.06277193933628669, 'deviance'],\n",
       " [28, 4, 0.005445788189169609, 0.002258808366805843, 'deviance'],\n",
       " [56, 1, 0.0006780193306440557, 0.9274466173670369, 'exponential'],\n",
       " [42, 4, 0.08952334707464486, 0.20644568894340298, 'deviance'],\n",
       " [68, 1, 0.0010637763908757617, 0.0037524397848558923, 'deviance'],\n",
       " [48, 4, 0.0016815858162959685, 0.27886812907463643, 'deviance'],\n",
       " [107, 5, 0.016812145780055444, 0.008608554188871567, 'exponential'],\n",
       " [10, 2, 0.051933898642812004, 0.2421867730253962, 'exponential'],\n",
       " [25, 3, 0.07191463533071865, 0.0922143588021903, 'deviance'],\n",
       " [120, 5, 0.0769701775233647, 0.8551443253205893, 'deviance'],\n",
       " [10, 2, 0.07842467548885194, 0.0011887833662717307, 'deviance'],\n",
       " [10, 4, 0.08121611587519112, 0.999, 'deviance'],\n",
       " [120, 1, 0.07773028929873592, 0.001, 'deviance'],\n",
       " [120, 1, 0.07607563983985653, 0.001, 'deviance'],\n",
       " [120, 1, 0.07630178890321913, 0.034960026718498675, 'deviance'],\n",
       " [114, 5, 0.07804002082510972, 0.001, 'deviance'],\n",
       " [120, 1, 0.07961597802092676, 0.999, 'deviance'],\n",
       " [120, 1, 0.08478538180012153, 0.999, 'deviance'],\n",
       " [120, 1, 0.08302332637820395, 0.999, 'deviance'],\n",
       " [120, 1, 0.018619934317209676, 0.999, 'exponential'],\n",
       " [120, 3, 0.1, 0.6020647450183829, 'exponential'],\n",
       " [120, 1, 0.1, 0.999, 'exponential'],\n",
       " [10, 1, 0.1, 0.030102208370517736, 'exponential'],\n",
       " [120, 1, 0.1, 0.001, 'exponential'],\n",
       " [120, 1, 0.05588582965612466, 0.0010360843005884316, 'exponential'],\n",
       " [120, 5, 0.05861947121605968, 0.001, 'exponential'],\n",
       " [120, 1, 0.06988996299286906, 0.999, 'exponential'],\n",
       " [73, 1, 0.020377591527230017, 0.999, 'exponential'],\n",
       " [120, 5, 0.005268311283046214, 0.999, 'exponential'],\n",
       " [120, 5, 0.008369524769796287, 0.999, 'exponential'],\n",
       " [95, 5, 0.00763759921995336, 0.999, 'exponential'],\n",
       " [120, 5, 0.017954346751129252, 0.10343737934252278, 'exponential'],\n",
       " [120, 1, 0.04005422506795059, 0.01319899511122053, 'deviance'],\n",
       " [120, 1, 0.053043018306605835, 0.999, 'deviance'],\n",
       " [120, 1, 0.05249386885930357, 0.999, 'deviance'],\n",
       " [120, 3, 0.05188550602926623, 0.999, 'deviance']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the evaluated hyperparamters\n",
    "\n",
    "optimizer.Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9171413381939697,\n",
       " -0.6256360598465861,\n",
       " -0.6256360598465861,\n",
       " -0.6256360598465861,\n",
       " -0.9296536796536796,\n",
       " -0.6256360598465861,\n",
       " -0.6256360598465861,\n",
       " -0.9347231715652767,\n",
       " -0.6256360598465861,\n",
       " -0.6256360598465861,\n",
       " -0.9221348826611985,\n",
       " -0.9146350725298094,\n",
       " -0.9321979190400244,\n",
       " -0.9673425989215462,\n",
       " -0.9246601351864511,\n",
       " -0.8994645705172021,\n",
       " -0.9497607655502392,\n",
       " -0.9472355130249867,\n",
       " -0.9472355130249867,\n",
       " -0.9246601351864511,\n",
       " -0.9497607655502392,\n",
       " -0.9572985494038125,\n",
       " -0.9472355130249867,\n",
       " -0.9371724766461608,\n",
       " -0.9598048150679729,\n",
       " -0.9572795625427205,\n",
       " -0.9170274170274171,\n",
       " -0.9572795625427205,\n",
       " -0.9447102604997341,\n",
       " -0.9246601351864511,\n",
       " -0.9472165261638946,\n",
       " -0.9296346927925875,\n",
       " -0.8969583048530416,\n",
       " -0.9195336826915774,\n",
       " -0.9145021645021645,\n",
       " -0.9271664008506114,\n",
       " -0.9497607655502392,\n",
       " -0.9472355130249867,\n",
       " -0.9497607655502392,\n",
       " -0.9472355130249867]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the accuracy\n",
    "\n",
    "optimizer.yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.917141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.057260</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.173717</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.679353</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>0.062772</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.929654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  min_samples_split  learning_rate         loss  \\\n",
       "0            68          4           0.007381       0.087048  exponential   \n",
       "1           118          2           0.000101       0.057260     deviance   \n",
       "2            17          3           0.000222       0.173717  exponential   \n",
       "3            42          4           0.000960       0.679353  exponential   \n",
       "4            38          5           0.053127       0.062772     deviance   \n",
       "\n",
       "   accuracy  \n",
       "0 -0.917141  \n",
       "1 -0.625636  \n",
       "2 -0.625636  \n",
       "3 -0.625636  \n",
       "4 -0.929654  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all together in one dataframe, so we can investigate further\n",
    "dim_names = ['n_estimators', 'max_depth', 'min_samples_split', 'learning_rate', 'loss']\n",
    "\n",
    "tmp = pd.concat([\n",
    "    pd.DataFrame(optimizer.Xi),\n",
    "    pd.Series(optimizer.yi),\n",
    "], axis=1)\n",
    "\n",
    "tmp.columns = dim_names + ['accuracy']\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate convergence of the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeHklEQVR4nO3df5RU5Z3n8fe3u7oLuqpbaGib5peIooA/Qkzr0Un8DRkTM4Oecd3MyeyQTVyys7NnZzaTrGQ9u5PZiXM02UQ3uzOZQzSK+WniJKPJxigQjMmsiWkTQKRBUCEK3dCi0tAtv7q/+0c91RRYTUPd21Tfqs/rnDp1761bXV+udn36Ps+9z2PujoiIVK+achcgIiLlpSAQEalyCgIRkSqnIBARqXIKAhGRKpcqdwGlmDx5ss+aNavcZYiIJMpzzz33uru3HL89kUEwa9YsOjo6yl2GiEiimNn2YtvVNCQiUuUUBCIiVU5BICJS5RQEIiJVTkEgIlLlFAQiIlVOQSAiUuUSeR9BqX7w29d4paev3GWU7EPvmsp5rY3lLkNEKkxVBcEP13WxZvPucpdREnfY8dYBvnjru8pdiohUmKoKgq999NJyl1CyG+59mv0HD5e7DBGpQOojSIiG+lr6Dg6UuwwRqUAKgoTIpFPsP3ik3GWISAVSECRENp2i/5CCQETipyBIiIb6lJqGRGRUKAgSIpuuVdOQiIwKBUFCZNIp+g4ewd3LXYqIVBgFQUJk0imODDqHBgbLXYqIVBgFQUJk6msB1E8gIrFTECREJp27969P/QQiErNIQWBmzWa20sy2hOeJw+w308yeNLNOM9toZrPC9gfN7BUzWxseC6LUU8myIQjUYSwicYt6RrAMWO3uc4DVYb2Yh4AvuPs84DKgcMCfT7v7gvBYG7GeipU/I9C9BCISt6hBsBhYEZZXADcdv4OZzQdS7r4SwN33u3t/xM+tOpl0ro9gv/oIRCRmUYOg1d27wnI30Fpkn/OAt8zs+2b2WzP7gpnVFrx+p5mtN7N7zCw93AeZ2VIz6zCzjp6enohlJ4/6CERktIwYBGa2ysw2FHksLtzPcxe4F7vIPQVcCXwKuBSYDXw0vPYZYG7Y3gzcPlwd7r7c3dvdvb2lpeUk/mmVJVOvIBCR0THiMNTuvnC418xsl5m1uXuXmbVxbNt/3mvAWnd/Obznn4HLgfsLziYOmtkD5MJCitAZgYiMlqhNQ48BS8LyEuDRIvv8GphgZvk/468DNgKE8MDMjFz/woaI9VSsfB9B3yH1EYhIvKIGwV3AIjPbAiwM65hZu5ndB+DuA+T+0l9tZs8DBnw1vP+bYdvzwGTgcxHrqVjpVC11tabLR0UkdpFmKHP3PcD1RbZ3ALcVrK8ELi6y33VRPr/aZNIp+hUEIhIz3VmcIJn6lC4fFZHYKQgSJJOuVWexiMROQZAgmXSKPt1ZLCIxUxAkSDbMSSAiEicFQYI01NdqGGoRiZ2CIEEy6ZQuHxWR2CkIEiSbTmn0URGJnYIgQRrqU2oaEpHYKQgSJJuu5dDAIIeOaN5iEYmPgiBBNPCciIwGBUGCDAWB+glEJEYKggQ5OieB+glEJD4KggQ5Ol2lzghEJD4KggTJqo9AREaBgiBBGkLTkO4lEJE4KQgSJH9GoKGoRSROCoIEGZquUk1DIhIjBUGC6PJRERkNCoIESadqqK0xnRGISKwUBAliZmQ0FLWIxCxSEJhZs5mtNLMt4XlikX2uNbO1BY8DZnZTeO1sM/uVmW01s4fNrD5KPdUgq6GoRSRmUc8IlgGr3X0OsDqsH8Pd17j7AndfAFwH9ANPhpfvBu5x93OBN4GPR6yn4mU0FLWIxCxqECwGVoTlFcBNI+x/C/C4u/ebmZELhkdO4f1VryGd0uWjIhKrqEHQ6u5dYbkbaB1h/w8D3w7Lk4C33D3/5+1rwLTh3mhmS82sw8w6enp6otScaNl0rTqLRSRWqZF2MLNVwJQiL91RuOLubmZ+gp/TBlwEPHGqRYafvxxYDtDe3j7s51S6TH2KPfv7y12GiFSQEYPA3RcO95qZ7TKzNnfvCl/0u0/wo24FfuDuh8P6HmCCmaXCWcF0YMcp1F6VMumU7iMQkVhFbRp6DFgSlpcAj55g3z/maLMQ7u7AGnL9BifzfiF3d7EuHxWROEUNgruARWa2BVgY1jGzdjO7L7+Tmc0CZgA/O+79twOfNLOt5PoM7o9YT8XL6PJREYnZiE1DJ+Lue4Dri2zvAG4rWN9GkY5gd38ZuCxKDdUmW5/i0JFBDg8MUler+wFFJDp9kyRMQxhvqF/NQyISEwVBwmTzs5Spw1hEYqIgSJiMZikTkZgpCBLm6AT2CgIRiYeCIGGOnhGoj0BE4qEgSJj8LGW6hFRE4qIgSJis+ghEJGYKgoRpCH0EGopaROKiIEiY/BmBhqIWkbgoCBJmXF0NNaamIRGJj4IgYcxMI5CKSKwUBAmUqU/pjEBEYqMgSCANRS0icVIQJFBWQ1GLSIwUBAnUUJ/S5aMiEhsFQQLlJqdR05CIxENBkEDZdK06i0UkNgqCBMqkddWQiMRHQZBAuo9AROKkIEigTH2KA4cHOTIwWO5SRKQCRAoCM2s2s5VmtiU8Tyyyz7VmtrbgccDMbgqvPWhmrxS8tiBKPdUiPxR13yF1GItIdFHPCJYBq919DrA6rB/D3de4+wJ3XwBcB/QDTxbs8un86+6+NmI9VSE/8JwuIRWROEQNgsXAirC8ArhphP1vAR539/6In1vVGjQngYjEKGoQtLp7V1juBlpH2P/DwLeP23anma03s3vMLD3cG81sqZl1mFlHT09PhJKTLzs0S5mahkQkuhGDwMxWmdmGIo/Fhfu5uwN+gp/TBlwEPFGw+TPAXOBSoBm4fbj3u/tyd2939/aWlpaRyq5omsBeROKUGmkHd1843GtmtsvM2ty9K3zR7z7Bj7oV+IG7Hy742fmziYNm9gDwqZOsu6pl1DQkIjGK2jT0GLAkLC8BHj3Bvn/Mcc1CITwwMyPXv7AhYj1VYSgI1FksIjGIGgR3AYvMbAuwMKxjZu1mdl9+JzObBcwAfnbc+79pZs8DzwOTgc9FrKcqZNRHICIxGrFp6ETcfQ9wfZHtHcBtBevbgGlF9rsuyudXq6yahkQkRrqzOIHG19ViBv0KAhGJgYIggcyMTL2GohaReCgIEiqjoahFJCYKgoTK1GsEUhGJh4IgoTQngYjERUGQULmmIfURiEh0CoKEyqZT7NcZgYjEQEGQUA31KQ1DLSKxUBAkVCaty0dFJB4KgoTK6vJREYmJgiChMukUbx8eYGBw2JG/RUROioIgofJzEqifQESiUhAk1NE5CdRPICLRKAgS6uhQ1DojEJFoFAQJpaYhEYmLgiCh8k1DOiMQkagUBAmVVR+BiMREQZBQ+T4C3UsgIlEpCBJKE9iLSFwUBAmV0bzFIhKTyEFgZs1mttLMtoTnicPs93kze8HMOs3sy2ZmYft7zOx5M9tauF1OrKEuf/mo+ghEJJo4zgiWAavdfQ6wOqwfw8x+D3gvcDFwIXApcHV4+SvAvwPmhMcNMdRU8WpqjEy9xhsSkejiCILFwIqwvAK4qcg+DowD6oE0UAfsMrM2oMndf+nuDjw0zPuliIa0hqIWkejiCIJWd+8Ky91A6/E7uPszwBqgKzyecPdOYBrwWsGur4Vt72BmS82sw8w6enp6Yig7+bIailpEYpA6mZ3MbBUwpchLdxSuuLub2TuGwzSzc4F5wPSwaaWZXQm8fbKFuvtyYDlAe3u7htwkP12lzghEJJqTCgJ3Xzjca2a2y8za3L0rNPXsLrLbzcAv3X1/eM/jwBXA1zkaDoTlHSdbfLVrqNcE9iISXRxNQ48BS8LyEuDRIvv8DrjazFJmVkeuo7gzNCn1mtnl4WqhPx3m/VJENp3SfQQiElkcQXAXsMjMtgALwzpm1m5m94V9HgFeAp4H1gHr3P2H4bX/ANwHbA37PB5DTVUhk05piAkRieykmoZOxN33ANcX2d4B3BaWB4BPDPP+DnKXlMopyqZrNeiciESmO4sTrKE+Rb+CQEQiUhAkWCadou/QAIOat1hEIlAQJFg2jEDaf1j9BCJSOgVBgjXUa+A5EYlOQZBgWY1AKiIxUBAkWEazlIlIDBQECZafpUyXkIpIFAqCBMuEPgKNQCoiUSgIEizfNKQzAhGJQkGQYFn1EYhIDBQECZbvI9BVQyIShYIgwYbuI1AfgYhEoCBIsNoaY3ydJqcRkWgUBAmX0XSVIhKRgiDhNF2liESlIEi4TH1K9xGISCQKgoTLplO6j0BEIlEQJFyuaUh9BCJSOgVBwjVoAnsRiUhBkHDZ+pQ6i0UkkkhBYGbNZrbSzLaE54nD7Pd5M3vBzDrN7MtmZmH7U2a22czWhseZUeqpRpl0Sk1DIhJJ1DOCZcBqd58DrA7rxzCz3wPeC1wMXAhcClxdsMtH3H1BeOyOWE/VyaRr6Tt0BHfNWywipYkaBIuBFWF5BXBTkX0cGAfUA2mgDtgV8XMlyKRTuMPbmrdYREoUNQha3b0rLHcDrcfv4O7PAGuArvB4wt07C3Z5IDQL/bd8k1ExZrbUzDrMrKOnpydi2ZVDQ1GLSFQjBoGZrTKzDUUeiwv381zbxDvaJ8zsXGAeMB2YBlxnZleGlz/i7hcBV4bHvxmuDndf7u7t7t7e0tJy0v/ASpcdGoFUZwQiUprUSDu4+8LhXjOzXWbW5u5dZtYGFGvjvxn4pbvvD+95HLgC+Lm77wifsc/MvgVcBjxUwr+jag2NQKozAhEpUdSmoceAJWF5CfBokX1+B1xtZikzqyPXUdwZ1icDhO0fAjZErKfqHJ2cRkEgIqWJGgR3AYvMbAuwMKxjZu1mdl/Y5xHgJeB5YB2wzt1/SK7j+AkzWw+sBXYAX41YT9XJ9xHopjIRKdWITUMn4u57gOuLbO8AbgvLA8AniuzTB7wnyufL0T4CDUUtIqXSncUJl+8j6FfTkIiUSEGQcLp8VESiUhAkXKZel4+KSDQKgoRL1daQTtWos1hESqYgqADZtEYgFZHSKQgqQEZBICIRKAgqQCad0uWjIlIyBUEFyNTX6oxAREqmIKgAmXSKfnUWi0iJFAQVIJtO6T4CESmZgqACZNK1uo9AREqmIKgADfUp3UcgIiVTEFSA/H0EmrdYREqhIKgAmXSKQYcDhwfLXYqIJJCCoAJkhoaiVvOQiJw6BUEFyOSHolY/gYiUQEFQATQUtYhEoSCoAEfnLdYlpCJy6hQEFaAhnZ+TQGcEInLqFAQVIKsJ7EUkgkhBYGbNZrbSzLaE54nD7He3mW0Ij39dsP1sM/uVmW01s4fNrD5KPdUq30fw8xdf57ntb+jMQEROSSri+5cBq939LjNbFtZvL9zBzG4ELgEWAGngKTN73N17gbuBe9z9O2b2j8DHga9ErKnqTMrUM7O5gYc7XuXhjlcxg7OaG5g/tYn5bU3Ma2viomlncGbTuHKXKiJjkEW5G9XMNgPXuHuXmbUBT7n7+cft82lgnLv/bVi/H3gC+B7QA0xx9yNmdgXwWXf//ZE+t7293Ts6OkquuxK5Ozv3HqBzZy8bu3rp7Mo9b9/TD0CNwZduXcBN755W5kpFpFzM7Dl3bz9+e9QzglZ37wrL3UBrkX3WAX9tZl8EGoBrgY3AJOAtd8+3Y7wGDPstZWZLgaUAM2fOjFh25TEzpk0Yz7QJ41k4/+h/hv0Hj7Cpq5f/+eRmPvW9dTRn6rnqvJYyVioiY82IfQRmtqqgfb/wsbhwP8+dWrzj9MLdnwR+DPw/4NvAM8ApX+fo7svdvd3d21ta9EV2srLpFO2zmln+p+2ce2aWP/vGc2zYsbfcZYnIGDJiELj7Qne/sMjjUWBXaBIiPO8e5mfc6e4L3H0RYMCLwB5ggpnlz0qmAzvi+EfJOzWNq2PFxy5jQkM9H33gWbbv6St3SSIyRkS9fPQxYElYXgI8evwOZlZrZpPC8sXAxcCT4QxiDXDLid4v8WltGseKj13GkUFnydee5fX9B8tdkoiMAVGD4C5gkZltARaGdcys3czuC/vUAT83s43AcuBPCvoFbgc+aWZbyfUZ3B+xHhnBuWdmuX/JpXT3HuBjD/5al5qKSLSrhspFVw1Ft2rjLpZ+vYMr57Rw35J26mp1b6FIpRvuqiH99lephfNb+bubL+JnL/Zw+z+t16Q2IlUs6uWjkmAfvmwmu3oPcs+qF6mrqWHBzAnUmlFTY9QY1NYYZkatGRMa6jh/SiOTs+lyly0iMVMQVLn/dP257Ok7yEPPbOfhjldH3H9ytp7zpzQyd0pTeG5kzpmNjK+vPQ3VishoUB+BAPD6/oMcHhhkYNBxh4FBZ9DzD+jZd5BN3fvY3N3Lpu59vLhr39DUmDWWG++oxnJnEjUWziRqCNuMGc3jmTuliblTGjk/PBrq9XeIyOk0WncWS4UYqcnnvNZG3nvu5KH1gUFn+54+NnfvY1P3PnoPHMYdBt1DiOSGvRh05/CA88rrfXy341X6D+XuJTSDmc0NzA1nF/OnNnHB1CamTRiPmY3qv1VEjqUgkJLU1hizW7LMbsnygYvaTuo9g4POa2++TWd3L5u797G5ex+d3b2s3LiLwXBiOqGhjgumNnHB1DOGns+enKG2RuEgMloUBHLa1NQYMyc1MHNSA79/wZSh7W8fGmBTdy8bdvaycedeXtjZy4P/so1DA7mmp/F1tcxta2R+W9PQiKpzpzSpX0IkJuojkDHp8MAgW3fv54WdvWzYsXdoNNV9B3I3wNUYnD05w/ypZzB94nhKPV8wg+kTG5jfluv8HlencJHKNVwfgYJAEsM9NC2FUNi4s5cXdvaye9+Bkn/mYOgYh1y4zG7JMq8tP49DI/OnNnFmo+ZxkMqgzmJJPDNjRnMDM5obeH9B01IU+X6LjV172bizl41d+/jN9jf54bqdQ/tMztYzd0ouGOaFiX7OaclSn9L9mFIZFARS1Qr7LW648Gin997+w7mzjq5eNnX10tndy4pntnPoSK7foq7WOPfMRmYXdGQXXuyUX2waXzd0hqGmJxmrFAQiRZzRUMcV50ziinMmDW07MjDIK6/3hRng9tEZZoJzOGaIjsLG1j37D7H/4HYgd6XVOS0Z5rflrobKd3xPzGiqbikvBYHISUrV1jCntZE5rY0sXnBy7xkcdF59sz80O+X6NH758hv889qjTU9tZ4w75oqo+VObmDGxgRpdMiuniYJAZBTV1BhnTcpw1qTMMfdb7Nl/8Ojc0iEknnqxZ6jjOptODfVJ5PsndDe2jBb9XyVSBpOyaa6c08KVc45Ou3rg8AAv7to3FAwbd/by/d/sGGpaMoNZkzLMnZILiAumNnHVeS0aQlwiUxCIjBHj6mq5ePoELp4+YWjb4KCz4623Q6f10X6Jn7zQjTvMbsnwmQ/MY+G8MzU0h5RM9xGIJFDfwSP8fEsPn//JZl5+vY8rZk/ijhvnceG0M8pdmoxhmphGpIJk0iluuLCNJ/7zVfzNH17Apu5e/uD//IK/+u46uveWfoOdVCedEYhUgL1vH+Yf1mzlgX/ZRk0NLL1yNp+4+hwyabX+ylEaYkKkCrz6Rj93/2QTP1rfRdO4FO+aMSEMl5G7LHX25AwpdS5XrVEJAjNrBh4GZgHbgFvd/c0i+90N3BhW/9bdHw7bHwSuBvaG1z7q7mtH+lwFgciJ/eZ3b/KdZ3/Hxq5eXuzePzSSa32qhvNbG5nX1jjsvQr5PmcreSi/6LLp2tyls21NZHVWE5vRGmtoGbDa3e8ys2Vh/fbjPvhG4BJgAZAGnjKzx929N+zyaXd/JGIdIlLgkpkTuWTmRCA3kuvLPX1s7NpLZ1fu8tRVnbt5o+9Qmas8ObMmNQzdbJc/s2ltHMdoXiRVbVdgRQ2CxcA1YXkF8BTHBQEwH3ja3Y8AR8xsPXAD8N2Iny0iJ6GutmZoetCb353b5mHmOAAvGBRjrLQUv9F36Jib7V7Y2cuPn+8+LZ+dTae47cqzWXrV7Kq5gS9q09Bb7j4hLBvwZn69YJ/3A38NLAIagGeBv3f3L4amoSuAg8BqYJm7Hxzms5YCSwFmzpz5nu3bt5dct4gkz74Dh9nUnTujebN/9M5mOrt6eeKFXbQ2pfmr95/PH10yvWJmyCu5j8DMVgHFxvy9A1hR+MVvZm+6+8QiP+MO4F8BPcBu4Nfufq+ZtQHdQD2wHHjJ3f/HSP8Y9RGIyGjq2PYGn/u/nax99S3mtTVxxwfn8b45k0d+4xg3Wp3Fm4Fr3L0rfKk/5e7nj/CebwHfcPcfH7f9GuBT7v6hkT5XQSAio83d+dH6Lu7+ySZee/Ntrjm/hf/6wXmc19pY7tJKNlqdxY8BS4C7wvOjRT64Fpjg7nvM7GLgYuDJ8FpbCBEDbgI2RKxHRCQWZsYfvGsqi+a38tAz2/jfP93KDfc+zbXnn3nS82UXdjobuSuy2s4YP9T5fXbBfBblFPWMYBK5Tt+ZwHZyl4++YWbtwL9399vMbBzwm/CW3rB9bXj/T4EWcsdobXht/0ifqzMCETnd3ug7xJdXb+HnW3o4qW9Nf+fiwKDTtfftoY76cXU1nD8lDD/e1sj8qWfw7hkTRm0Ict1QJiIyBhw6MsjW3fuPmXu7s7uXt/oPA3DRtDO448Z5XD570gg/6dQpCERExih3p2vvAX6x9XXuXfkiO/ce4P3zW1n2gbnMbsnG9jkKAhGRBDhweID7f/EK/7BmKwePDPInl5/FX1w/J5YpTTX6qIhIAoyrq+XPrz2Xpz59LbdeOoOHntnG1V9Yw1effpmDRwZG5TMVBCIiY1BLY5q/u/kifvKXV3HJWRO588edLPrS02zu3hf7ZykIRETGsPNaG3nw317G1z9+GbMmZ5jRPD72z6iOgTRERBLu+Dmu46QzAhGRKqcgEBGpcgoCEZEqpyAQEalyCgIRkSqnIBARqXIKAhGRKqcgEBGpcokcdM7MesjNf1CKycDrMZYTJ9VWGtVWGtVWmiTXdpa7v+OutEQGQRRm1lFs9L2xQLWVRrWVRrWVphJrU9OQiEiVUxCIiFS5agyC5eUu4ARUW2lUW2lUW2kqrraq6yMQEZFjVeMZgYiIFFAQiIhUuaoKAjO7wcw2m9lWM1tW7noKmdk2M3vezNaaWUeZa/mame02sw0F25rNbKWZbQnPE8dQbZ81sx3h2K01sw+WqbYZZrbGzDaa2Qtm9hdhe9mP3QlqK/uxM7NxZvasma0Ltf1N2H62mf0q/L4+bGbRZ2+Pr7YHzeyVguO24HTXFuqoNbPfmtmPwnppx8zdq+IB1AIvAbOBemAdML/cdRXUtw2YXO46Qi1XAZcAGwq2fR5YFpaXAXePodo+C3xqDBy3NuCSsNwIvAjMHwvH7gS1lf3YAQZkw3Id8CvgcuC7wIfD9n8E/mwM1fYgcMsY+H/uk8C3gB+F9ZKOWTWdEVwGbHX3l939EPAdYHGZaxqT3P1p4I3jNi8GVoTlFcBNp7OmvGFqGxPcvcvdfxOW9wGdwDTGwLE7QW1l5zn7w2pdeDhwHfBI2F6u4zZcbWVnZtOBG4H7wrpR4jGrpiCYBrxasP4aY+QXIXDgSTN7zsyWlruYIlrdvSssdwOt5SymiP9oZutD01FZmq0Kmdks4N3k/oIcU8fuuNpgDBy70MSxFtgNrCR39v6Wux8Ju5Tt9/X42tw9f9zuDMftHjNLl6G0e4H/AgyG9UmUeMyqKQjGuve5+yXAB4A/N7Oryl3QcDx33jkm/ioKvgKcAywAuoAvlrMYM8sC/wT8pbv3Fr5W7mNXpLYxcezcfcDdFwDTyZ29zy1HHcUcX5uZXQh8hlyNlwLNwO2nsyYz+xCw292fi+PnVVMQ7ABmFKxPD9vGBHffEZ53Az8g98swluwyszaA8Ly7zPUMcfdd4Zd1EPgqZTx2ZlZH7ov2m+7+/bB5TBy7YrWNpWMX6nkLWANcAUwws1R4qey/rwW13RCa2tzdDwIPcPqP23uBPzSzbeSaua8D/hclHrNqCoJfA3NCr3o98GHgsTLXBICZZcysMb8MvB/YcOJ3nXaPAUvC8hLg0TLWcoz8l2xwM2U6dqGN9n6g092/VPBS2Y/dcLWNhWNnZi1mNiEsjwcWkevDWAPcEnYr13ErVtumgmA3cu3wp/W4uftn3H26u88i9132U3f/CKUes3L3ep/OB/BBcldLvATcUe56CuqaTe4qpnXAC+WuDfg2uWaCw+TaGT9Orv1xNbAFWAU0j6Havg48D6wn96XbVqba3keu2Wc9sDY8PjgWjt0Jaiv7sQMuBn4batgA/PewfTbwLLAV+B6QHkO1/TQctw3ANwhXFpXp/7trOHrVUEnHTENMiIhUuWpqGhIRkSIUBCIiVU5BICJS5RQEIiJVTkEgIlLlFAQiIlVOQSAiUuX+P1oicUShYlA9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp['accuracy'].sort_values(ascending=False).reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trade-off with parallelization, is that we will not optimize the search after each evaluation of f(x), instead after, in this case 4, evaluations of f(x). Thus, we may need to perform more evaluations to find the optima. But, because we do it in parallel, overall, we reduce wall time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.076970</td>\n",
       "      <td>0.855144</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.967343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.602065</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.959805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084785</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.957299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.957280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.957280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079616</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.949761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040054</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.949761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052494</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.949761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.949761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.034960</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.947236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076076</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.947236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051886</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.947236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053043</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.947236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083023</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.947236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069890</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.947217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055886</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.944710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.937172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0.089523</td>\n",
       "      <td>0.206446</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.934723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071915</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.932198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>0.062772</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.929654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.929635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>0.103437</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.927166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058619</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.924660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>0.078040</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.924660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.078425</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.924660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.922135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.919534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.917141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.030102</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.917027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.051934</td>\n",
       "      <td>0.242187</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.914635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.914502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081216</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.899465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.896958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.278868</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.927447</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.679353</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.173717</td>\n",
       "      <td>exponential</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.057260</td>\n",
       "      <td>deviance</td>\n",
       "      <td>-0.625636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth  min_samples_split  learning_rate         loss  \\\n",
       "13           120          5           0.076970       0.855144     deviance   \n",
       "24           120          3           0.100000       0.602065  exponential   \n",
       "21           120          1           0.084785       0.999000     deviance   \n",
       "25           120          1           0.100000       0.999000  exponential   \n",
       "27           120          1           0.100000       0.001000  exponential   \n",
       "20           120          1           0.079616       0.999000     deviance   \n",
       "36           120          1           0.040054       0.013199     deviance   \n",
       "38           120          1           0.052494       0.999000     deviance   \n",
       "16           120          1           0.077730       0.001000     deviance   \n",
       "18           120          1           0.076302       0.034960     deviance   \n",
       "17           120          1           0.076076       0.001000     deviance   \n",
       "39           120          3           0.051886       0.999000     deviance   \n",
       "37           120          1           0.053043       0.999000     deviance   \n",
       "22           120          1           0.083023       0.999000     deviance   \n",
       "30           120          1           0.069890       0.999000  exponential   \n",
       "28           120          1           0.055886       0.001036  exponential   \n",
       "23           120          1           0.018620       0.999000  exponential   \n",
       "7             42          4           0.089523       0.206446     deviance   \n",
       "12            25          3           0.071915       0.092214     deviance   \n",
       "4             38          5           0.053127       0.062772     deviance   \n",
       "31            73          1           0.020378       0.999000  exponential   \n",
       "35           120          5           0.017954       0.103437  exponential   \n",
       "29           120          5           0.058619       0.001000  exponential   \n",
       "19           114          5           0.078040       0.001000     deviance   \n",
       "14            10          2           0.078425       0.001189     deviance   \n",
       "10           107          5           0.016812       0.008609  exponential   \n",
       "33           120          5           0.008370       0.999000  exponential   \n",
       "0             68          4           0.007381       0.087048  exponential   \n",
       "26            10          1           0.100000       0.030102  exponential   \n",
       "11            10          2           0.051934       0.242187  exponential   \n",
       "34            95          5           0.007638       0.999000  exponential   \n",
       "15            10          4           0.081216       0.999000     deviance   \n",
       "32           120          5           0.005268       0.999000  exponential   \n",
       "9             48          4           0.001682       0.278868     deviance   \n",
       "8             68          1           0.001064       0.003752     deviance   \n",
       "6             56          1           0.000678       0.927447  exponential   \n",
       "5             28          4           0.005446       0.002259     deviance   \n",
       "3             42          4           0.000960       0.679353  exponential   \n",
       "2             17          3           0.000222       0.173717  exponential   \n",
       "1            118          2           0.000101       0.057260     deviance   \n",
       "\n",
       "    accuracy  \n",
       "13 -0.967343  \n",
       "24 -0.959805  \n",
       "21 -0.957299  \n",
       "25 -0.957280  \n",
       "27 -0.957280  \n",
       "20 -0.949761  \n",
       "36 -0.949761  \n",
       "38 -0.949761  \n",
       "16 -0.949761  \n",
       "18 -0.947236  \n",
       "17 -0.947236  \n",
       "39 -0.947236  \n",
       "37 -0.947236  \n",
       "22 -0.947236  \n",
       "30 -0.947217  \n",
       "28 -0.944710  \n",
       "23 -0.937172  \n",
       "7  -0.934723  \n",
       "12 -0.932198  \n",
       "4  -0.929654  \n",
       "31 -0.929635  \n",
       "35 -0.927166  \n",
       "29 -0.924660  \n",
       "19 -0.924660  \n",
       "14 -0.924660  \n",
       "10 -0.922135  \n",
       "33 -0.919534  \n",
       "0  -0.917141  \n",
       "26 -0.917027  \n",
       "11 -0.914635  \n",
       "34 -0.914502  \n",
       "15 -0.899465  \n",
       "32 -0.896958  \n",
       "9  -0.625636  \n",
       "8  -0.625636  \n",
       "6  -0.625636  \n",
       "5  -0.625636  \n",
       "3  -0.625636  \n",
       "2  -0.625636  \n",
       "1  -0.625636  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.sort_values(by='accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html",
   "language": "python",
   "name": "html"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
